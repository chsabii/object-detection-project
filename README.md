ğŸ  Indoor Object Detection Project

ğŸŒŸ Overview

This project involves the implementation of an indoor object detection system using the YOLOv8 model. The primary goal is to detect and classify various objects within indoor environments, leveraging state-of-the-art deep learning techniques for accurate predictions.

The project is developed under the supervision of The Islamia University of Bahawalpur and includes a comprehensive pipeline for data preparation, model training, evaluation, and deployment using modern web technologies such as FastAPI and Streamlit.

ğŸ“‚ Dataset

The dataset used for this project contains labeled images of various indoor objects. It is structured as follows:

ğŸ“¸ Training Set: Images and corresponding labels for training.

ğŸ§ª Validation Set: Images and labels for evaluating the model during training.

ğŸ§¾ Test Set: Unseen images for final performance assessment.

ğŸª Classes:

ğŸšª Door

ğŸšª Cabinet Door

ğŸ§Š Refrigerator Door

ğŸªŸ Window

ğŸª‘ Chair

ğŸ›‹ï¸ Table

ğŸ—„ï¸ Cabinet

ğŸ›‹ï¸ Couch

ğŸšª Opened Door

ğŸ—ï¸ Pole

ğŸ¤– Model

The project utilizes the YOLOv8 Medium (yolov8m) architecture for object detection. The model is fine-tuned on the custom dataset to optimize performance for the specific indoor objects.

ğŸ”‘ Key Features:

ğŸ‹ï¸ Pre-trained weights (yolov8m.pt) for transfer learning.

âš™ï¸ Hyperparameter tuning, including epochs, learning rate, and batch size.

ğŸ“Š Performance metrics such as mAP (Mean Average Precision), recall, and F1-score for validation.

ğŸ› ï¸ Pipeline

ğŸ“Š Data Visualization

Bounding boxes and labels are visualized on random samples from the training dataset to ensure data quality.

ğŸ¯ Model Training

Training configuration is defined in yolo.yaml.

Parameters:

ğŸ•’ Epochs: 160

â³ Patience: 20

ğŸ“¦ Batch Size: 16

ğŸš€ Learning Rate: 0.0003

ğŸ–¼ï¸ Image Size: 640px

Results and metrics (e.g., confusion matrix) are saved for analysis.

ğŸ“ˆ Evaluation

Validation metrics include:

mAP @ 0.5:0.95

mAP @ 0.5

mAP @ 0.7

ğŸ”„ Recall

ğŸ’¡ F1-Score

ğŸ” Inference

Inference is performed on test images, and results are visualized with bounding boxes and class labels.

ğŸš€ Deployment

ğŸŒ FastAPI Endpoint

The model is deployed as an API endpoint using FastAPI.

Features include:

ğŸ“¤ Uploading images via HTTP requests.

ğŸ” Returning predictions with object names, confidence scores, and bounding box coordinates.

ğŸ–¥ï¸ Streamlit Frontend

A user-friendly web interface built with Streamlit.

Allows users to:

ğŸ“¤ Upload images.

ğŸ–¼ï¸ Visualize detection results in real time.

ğŸ“Š Results

Training results are visualized through:

ğŸ“‰ Loss curves

ğŸ“Š Confusion matrix

Final model metrics:

ğŸ“ˆ Mean Average Precision @ 0.5:0.95: [value]

ğŸ”„ Recall: [value]

ğŸ’¡ F1-Score: [value]

ğŸ› ï¸ Tools and Libraries

YOLOv8: ğŸ¤– Object detection framework.

FastAPI: ğŸŒ API development.

Streamlit: ğŸ–¥ï¸ Frontend interface.

PyCOCOtools, NumPy, Pandas, Matplotlib, OpenCV: ğŸ“Š Data processing and visualization.

WandB: ğŸ“ˆ Experiment tracking.

ğŸ« Supervision

This project is supervised by the esteemed faculty of The Islamia University of Bahawalpur.

ğŸ”® Future Work

ğŸ“¹ Integration with real-time video streams.

ğŸ–¥ï¸ Deployment on edge devices.

ğŸŒ Expansion to additional object classes and domains.

ğŸ™ Acknowledgments

Special thanks to The Islamia University of Bahawalpur for their support and guidance throughout this project.
